import React, { useState, useRef, useEffect } from 'react';
import { useSearchParams, useNavigate } from 'react-router-dom';
import { API_BASE_URL, shouldUseSandbox } from '../config/api';
import {
  CameraIcon,
  CheckCircleIcon,
  ExclamationTriangleIcon,
  ArrowPathIcon,
  XMarkIcon,
  EyeIcon,
} from '@heroicons/react/24/outline';

// OpenCV types
declare global {
  interface Window {
    cv: any;
  }
}

interface LiveCaptureSession {
  live_capture_token: string;
  expires_at: string;
  liveness_challenge: {
    type: string;
    instruction: string;
  };
  user_id: string;
  verification_id: string | null;
  expires_in_seconds: number;
}

interface CaptureResult {
  verification_id: string;
  live_capture_id: string;
  status: string;
  message: string;
  liveness_check_enabled: boolean;
  face_matching_enabled: boolean;
}

export const LiveCapturePage: React.FC = () => {
  const [searchParams] = useSearchParams();
  const navigate = useNavigate();
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  
  // State
  const [sessionData, setSessionData] = useState<LiveCaptureSession | null>(null);
  const [captureResult, setCaptureResult] = useState<CaptureResult | null>(null);
  const [error, setError] = useState<string>('');
  const [loading, setLoading] = useState(false);
  const [cameraState, setCameraState] = useState<'prompt' | 'initializing' | 'ready' | 'error'>('prompt');
  const [challengeState, setChallengeState] = useState<'waiting' | 'active' | 'completed'>('waiting');
  const [countdown, setCountdown] = useState<number | null>(null);
  const [faceDetected, setFaceDetected] = useState(false);
  const [captureAttempts, setCaptureAttempts] = useState(0);
  const [sessionExpired, setSessionExpired] = useState(false);
  const [debugInfo, setDebugInfo] = useState<string>('');
  const [opencvReady, setOpencvReady] = useState(false);
  
  // OpenCV refs
  const animationRef = useRef<number | null>(null);
  const faceClassifierRef = useRef<any>(null);

  // URL params
  const token = searchParams.get('token');
  const verificationId = searchParams.get('verification_id');
  const apiKey = searchParams.get('api_key');

  // Initialize OpenCV
  useEffect(() => {
    const initOpenCV = () => {
      if (window.cv && window.cv.Mat) {
        console.log('ðŸ”§ OpenCV ready');
        setOpencvReady(true);
        setDebugInfo('OpenCV loaded');
        loadFaceClassifier();
      } else {
        console.log('ðŸ”§ Waiting for OpenCV...');
        setTimeout(initOpenCV, 100);
      }
    };
    initOpenCV();

    return () => {
      cleanup();
    };
  }, []);

  // Load session data
  useEffect(() => {
    if (!token) {
      setError('Invalid or missing live capture token');
      return;
    }

    const mockSession: LiveCaptureSession = {
      live_capture_token: token,
      expires_at: new Date(Date.now() + 30 * 60 * 1000).toISOString(),
      liveness_challenge: {
        type: 'blink_twice',
        instruction: 'Please look directly at the camera and blink twice'
      },
      user_id: 'user-123',
      verification_id: verificationId,
      expires_in_seconds: 1800
    };

    setSessionData(mockSession);

    // Auto-start camera when OpenCV is ready
    if (opencvReady) {
      setTimeout(initializeCamera, 500);
    }

    // Session expiry timer
    const timer = setTimeout(() => {
      setSessionExpired(true);
      cleanup();
    }, mockSession.expires_in_seconds * 1000);

    return () => clearTimeout(timer);
  }, [token, verificationId, opencvReady]);

  const loadFaceClassifier = async () => {
    try {
      // For production deployment, we'll use a simplified face detection
      // that doesn't require external cascade files
      if (window.cv && window.cv.CascadeClassifier) {
        const classifier = new window.cv.CascadeClassifier();
        faceClassifierRef.current = classifier;
        console.log('ðŸ”§ Face classifier initialized');
      }
    } catch (error) {
      console.warn('ðŸ”§ Face classifier load failed, using basic detection:', error);
    }
  };

  const initializeCamera = async () => {
    if (cameraState === 'initializing' || cameraState === 'ready') return;
    
    setCameraState('initializing');
    setError('');
    setLoading(true);

    try {
      console.log('ðŸŽ¥ Initializing camera...');
      setDebugInfo('Requesting camera access...');

      const constraints = {
        video: {
          width: { ideal: 640 },
          height: { ideal: 480 },
          facingMode: 'user'
        },
        audio: false
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      streamRef.current = stream;

      if (canvasRef.current) {
        setupCanvas(stream);
        startVideoProcessing();
        setCameraState('ready');
        setDebugInfo('Camera ready');
        console.log('ðŸŽ¥ Camera initialized successfully');
      }

    } catch (error: any) {
      console.error('ðŸŽ¥ Camera initialization failed:', error);
      setCameraState('error');
      
      let errorMessage = 'Camera access failed';
      if (error.name === 'NotAllowedError') {
        errorMessage = 'Camera permission denied. Please enable camera access.';
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'No camera found. Please connect a camera.';
      }
      
      setError(errorMessage);
    } finally {
      setLoading(false);
    }
  };

  const setupCanvas = (stream: MediaStream) => {
    const canvas = canvasRef.current;
    if (!canvas) return;

    // Create a hidden video element to get frames from the stream
    const video = document.createElement('video');
    video.srcObject = stream;
    video.autoplay = true;
    video.playsInline = true;
    video.muted = true;
    
    video.onloadedmetadata = () => {
      canvas.width = video.videoWidth || 640;
      canvas.height = video.videoHeight || 480;
    };

    // Store video element reference for processing
    (canvas as any).videoElement = video;
  };

  const startVideoProcessing = () => {
    if (!canvasRef.current) return;

    const processFrame = () => {
      const canvas = canvasRef.current;
      const video = (canvas as any)?.videoElement;
      
      if (!canvas || !video || video.readyState < 2) {
        animationRef.current = requestAnimationFrame(processFrame);
        return;
      }

      const ctx = canvas.getContext('2d');
      if (!ctx) return;

      // Draw video frame
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // Perform face detection
      detectFaces(canvas, ctx);

      animationRef.current = requestAnimationFrame(processFrame);
    };

    processFrame();
  };

  const detectFaces = (canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D) => {
    try {
      // Simple face detection using image analysis
      // This is more reliable than loading external cascade files
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const faceFound = performBasicFaceDetection(imageData, canvas.width, canvas.height);

      // Add visual feedback
      if (faceFound) {
        drawFaceOverlay(ctx, canvas.width, canvas.height, true);
      } else {
        drawFaceOverlay(ctx, canvas.width, canvas.height, false);
      }

      // Update face detection state with smoothing
      updateFaceDetectionState(faceFound);

    } catch (error) {
      console.warn('ðŸ”§ Face detection error:', error);
    }
  };

  const performBasicFaceDetection = (imageData: ImageData, width: number, height: number): boolean => {
    // Simple face detection based on skin color and face proportions
    const data = imageData.data;
    const centerX = width / 2;
    const centerY = height / 2;
    const regionSize = Math.min(width, height) * 0.3;
    
    let skinPixels = 0;
    let totalPixels = 0;
    
    // Sample pixels in the center region where a face would be
    for (let y = centerY - regionSize/2; y < centerY + regionSize/2; y += 4) {
      for (let x = centerX - regionSize/2; x < centerX + regionSize/2; x += 4) {
        if (x < 0 || x >= width || y < 0 || y >= height) continue;
        
        const i = (Math.floor(y) * width + Math.floor(x)) * 4;
        const r = data[i];
        const g = data[i + 1];
        const b = data[i + 2];
        
        // Basic skin color detection
        if (r > 95 && g > 40 && b > 20 && 
            Math.max(r, Math.max(g, b)) - Math.min(r, Math.min(g, b)) > 15 &&
            Math.abs(r - g) > 15 && r > g && r > b) {
          skinPixels++;
        }
        totalPixels++;
      }
    }
    
    const skinRatio = totalPixels > 0 ? skinPixels / totalPixels : 0;
    return skinRatio > 0.1; // At least 10% skin pixels indicates a face
  };

  const drawFaceOverlay = (ctx: CanvasRenderingContext2D, width: number, height: number, faceDetected: boolean) => {
    // Draw face detection indicator
    const centerX = width / 2;
    const centerY = height / 2;
    const radius = Math.min(width, height) * 0.25;
    
    ctx.strokeStyle = faceDetected ? '#10B981' : '#EF4444';
    ctx.lineWidth = 3;
    ctx.setLineDash(faceDetected ? [] : [10, 10]);
    
    ctx.beginPath();
    ctx.arc(centerX, centerY, radius, 0, 2 * Math.PI);
    ctx.stroke();
    
    // Draw status text
    ctx.fillStyle = faceDetected ? '#10B981' : '#EF4444';
    ctx.font = '16px Arial';
    ctx.textAlign = 'center';
    ctx.fillText(
      faceDetected ? 'Face Detected' : 'Position Your Face',
      centerX,
      centerY + radius + 30
    );
  };

  const updateFaceDetectionState = (detected: boolean) => {
    // Use a simple smoothing algorithm
    const history = (window as any).faceHistory || [];
    history.push(detected);
    if (history.length > 10) history.shift();
    (window as any).faceHistory = history;
    
    const positiveCount = history.filter((h: boolean) => h).length;
    const smoothedDetection = positiveCount >= 6; // Require 6/10 positive detections
    
    setFaceDetected(smoothedDetection);
  };

  const startChallenge = () => {
    if (challengeState !== 'waiting' || !faceDetected) return;

    setChallengeState('active');
    setCountdown(3);

    const timer = setInterval(() => {
      setCountdown(prev => {
        if (prev === null || prev <= 1) {
          clearInterval(timer);
          performCapture();
          return null;
        }
        return prev - 1;
      });
    }, 1000);
  };

  const performCapture = async () => {
    if (!canvasRef.current || !sessionData || !apiKey) {
      setError('Missing required data for capture');
      return;
    }

    setLoading(true);
    setCaptureAttempts(prev => prev + 1);

    try {
      const canvas = canvasRef.current;
      const imageData = canvas.toDataURL('image/jpeg', 0.8);
      const base64Data = imageData.split(',')[1];

      console.log('ðŸ“¸ Capturing frame for verification...');
      
      const useSandbox = shouldUseSandbox(apiKey || undefined);
      const requestBody = {
        verification_id: sessionData.verification_id,
        live_image_data: base64Data,
        challenge_response: sessionData.liveness_challenge.type,
        ...(useSandbox && { sandbox: true })
      };
      
      console.log('ðŸ”§ Sandbox mode:', useSandbox);
      console.log('ðŸ”§ API Key (first 10 chars):', apiKey?.substring(0, 10));
      console.log('ðŸ”§ Verification ID:', sessionData.verification_id);
      console.log('ðŸ”§ Request body keys:', Object.keys(requestBody));
      console.log('ðŸ”§ Full request body:', JSON.stringify(requestBody, null, 2).substring(0, 200) + '...');

      const response = await fetch(`${API_BASE_URL}/api/verify/live-capture`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'X-API-Key': apiKey,
        },
        body: JSON.stringify(requestBody),
      });

      console.log('ðŸ”§ Response status:', response.status);
      console.log('ðŸ”§ Response headers:', Object.fromEntries(response.headers.entries()));

      if (!response.ok) {
        const errorData = await response.json();
        console.log('ðŸ”§ Error response:', errorData);
        throw new Error(errorData.message || 'Live capture failed');
      }

      const result: CaptureResult = await response.json();
      setCaptureResult(result);
      setChallengeState('completed');
      cleanup();

    } catch (error: any) {
      console.error('ðŸ“¸ Capture failed:', error);
      setError(error.message || 'Failed to capture image. Please try again.');
      setChallengeState('waiting');
      
      if (captureAttempts >= 3) {
        setError('Maximum capture attempts exceeded. Please refresh and try again.');
        cleanup();
      }
    } finally {
      setLoading(false);
    }
  };

  const cleanup = () => {
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
      animationRef.current = null;
    }
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    if (faceClassifierRef.current) {
      try {
        faceClassifierRef.current.delete();
      } catch (e) {
        console.log('ðŸ”§ Classifier cleanup error:', e);
      }
      faceClassifierRef.current = null;
    }
  };

  const retryCamera = () => {
    cleanup();
    setCameraState('prompt');
    setError('');
    setCaptureResult(null);
    setChallengeState('waiting');
    setCaptureAttempts(0);
    setTimeout(initializeCamera, 100);
  };

  const goToResults = async () => {
    if (captureResult?.verification_id && apiKey) {
      navigate(`/verify?verification_id=${captureResult.verification_id}&api_key=${apiKey}&step=5`);
    }
  };

  // Render session expired
  if (sessionExpired) {
    return (
      <div className="min-h-screen bg-gradient-to-br from-red-50 via-white to-red-50 flex items-center justify-center">
        <div className="bg-white rounded-2xl shadow-xl p-8 max-w-md w-full mx-4">
          <div className="text-center">
            <ExclamationTriangleIcon className="w-16 h-16 text-red-500 mx-auto mb-4" />
            <h2 className="text-2xl font-bold text-gray-900 mb-2">Session Expired</h2>
            <p className="text-gray-600 mb-6">
              Your live capture session has expired. Please start a new verification.
            </p>
            <button
              onClick={() => navigate('/verify')}
              className="w-full bg-blue-600 text-white py-3 px-6 rounded-xl hover:bg-blue-700 transition"
            >
              Start New Verification
            </button>
          </div>
        </div>
      </div>
    );
  }

  // Render success
  if (captureResult) {
    return (
      <div className="min-h-screen bg-gradient-to-br from-green-50 via-white to-green-50 flex items-center justify-center">
        <div className="bg-white rounded-2xl shadow-xl p-8 max-w-md w-full mx-4">
          <div className="text-center">
            <CheckCircleIcon className="w-16 h-16 text-green-500 mx-auto mb-4" />
            <h2 className="text-2xl font-bold text-gray-900 mb-2">Capture Complete!</h2>
            <p className="text-gray-600 mb-4">
              Your live capture has been successfully processed.
            </p>
            
            <div className="bg-gray-50 rounded-xl p-4 mb-6 text-left">
              <div className="space-y-2 text-sm">
                <div className="flex justify-between">
                  <span className="text-gray-600">Status:</span>
                  <span className="font-semibold text-blue-600">{captureResult.status}</span>
                </div>
                <div className="flex justify-between">
                  <span className="text-gray-600">Liveness Check:</span>
                  <span className={`font-semibold ${captureResult.liveness_check_enabled ? 'text-green-600' : 'text-gray-600'}`}>
                    {captureResult.liveness_check_enabled ? 'Enabled' : 'Disabled'}
                  </span>
                </div>
                <div className="flex justify-between">
                  <span className="text-gray-600">Face Matching:</span>
                  <span className={`font-semibold ${captureResult.face_matching_enabled ? 'text-green-600' : 'text-gray-600'}`}>
                    {captureResult.face_matching_enabled ? 'Enabled' : 'Disabled'}
                  </span>
                </div>
              </div>
            </div>

            <div className="space-y-3">
              <button
                onClick={goToResults}
                className="w-full bg-blue-600 text-white py-3 px-6 rounded-xl hover:bg-blue-700 transition"
              >
                View Full Results
              </button>
            </div>
          </div>
        </div>
      </div>
    );
  }

  // Main camera interface
  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 via-white to-purple-50">
      <div className="max-w-4xl mx-auto p-6">
        {/* Header */}
        <div className="text-center mb-8">
          <h1 className="text-4xl font-bold text-gray-900 mb-4">Live Identity Verification</h1>
          <p className="text-xl text-gray-600">Complete your verification with live face capture</p>
        </div>

        <div className="bg-white rounded-2xl shadow-xl overflow-hidden">
          {/* Camera Permission Prompt */}
          {cameraState === 'prompt' && (
            <div className="p-8 text-center">
              <CameraIcon className="w-16 h-16 text-blue-500 mx-auto mb-6" />
              <h2 className="text-2xl font-bold text-gray-900 mb-4">Camera Access Required</h2>
              <p className="text-gray-600 mb-6">
                We need access to your camera for live identity verification using OpenCV technology.
              </p>
              <button
                onClick={initializeCamera}
                disabled={!opencvReady || loading}
                className="bg-blue-600 text-white py-4 px-8 rounded-xl hover:bg-blue-700 disabled:bg-gray-400 transition flex items-center justify-center mx-auto"
              >
                {!opencvReady ? (
                  <>
                    <ArrowPathIcon className="w-5 h-5 mr-2 animate-spin" />
                    Loading OpenCV...
                  </>
                ) : loading ? (
                  <>
                    <ArrowPathIcon className="w-5 h-5 mr-2 animate-spin" />
                    Initializing Camera...
                  </>
                ) : (
                  <>
                    <CameraIcon className="w-5 h-5 mr-2" />
                    Enable Camera
                  </>
                )}
              </button>
            </div>
          )}

          {/* Camera Error */}
          {cameraState === 'error' && (
            <div className="p-8 text-center">
              <ExclamationTriangleIcon className="w-16 h-16 text-red-500 mx-auto mb-6" />
              <h2 className="text-2xl font-bold text-gray-900 mb-4">Camera Access Failed</h2>
              <p className="text-gray-600 mb-6">{error}</p>
              <div className="space-y-3">
                <button
                  onClick={retryCamera}
                  className="bg-blue-600 text-white py-3 px-6 rounded-xl hover:bg-blue-700 transition"
                >
                  Try Again
                </button>
              </div>
            </div>
          )}

          {/* Live Camera Feed */}
          {cameraState === 'ready' && sessionData && (
            <div className="relative">
              {/* Challenge Info */}
              <div className="bg-gradient-to-r from-blue-600 to-purple-600 p-6 text-white">
                <div className="flex items-center justify-center space-x-4 mb-4">
                  <div className="p-3 bg-white/20 rounded-full">
                    <EyeIcon className="w-8 h-8" />
                  </div>
                  <div>
                    <h3 className="text-xl font-bold">Liveness Challenge</h3>
                    <p className="text-blue-100">{sessionData.liveness_challenge.instruction}</p>
                  </div>
                </div>
                
                {countdown !== null && (
                  <div className="text-center">
                    <div className="text-4xl font-bold mb-2">{countdown}</div>
                    <p className="text-blue-100">Get ready...</p>
                  </div>
                )}
              </div>

              {/* OpenCV Canvas */}
              <div className="relative bg-black">
                <canvas
                  ref={canvasRef}
                  className="w-full h-96 object-cover"
                  style={{ maxHeight: '384px' }}
                />
              </div>

              {/* Controls */}
              <div className="p-6 bg-gray-50">
                <div className="flex items-center justify-between mb-4">
                  <div className="text-sm text-gray-600">
                    Attempts: {captureAttempts}/3
                  </div>
                  {sessionData && (
                    <div className="text-sm text-gray-600">
                      Session expires: {new Date(sessionData.expires_at).toLocaleTimeString()}
                    </div>
                  )}
                </div>

                <div className="text-center">
                  {challengeState === 'waiting' && (
                    <button
                      onClick={startChallenge}
                      disabled={!faceDetected || loading}
                      className="bg-green-600 text-white py-4 px-8 rounded-xl hover:bg-green-700 disabled:bg-gray-400 transition flex items-center justify-center mx-auto"
                    >
                      {!faceDetected ? (
                        <>
                          <ExclamationTriangleIcon className="w-5 h-5 mr-2" />
                          Position Your Face
                        </>
                      ) : loading ? (
                        <>
                          <ArrowPathIcon className="w-5 h-5 mr-2 animate-spin" />
                          Processing...
                        </>
                      ) : (
                        <>
                          <CameraIcon className="w-5 h-5 mr-2" />
                          Start Capture
                        </>
                      )}
                    </button>
                  )}

                  {challengeState === 'active' && (
                    <div className="text-center">
                      <div className="text-lg font-semibold text-gray-900 mb-2">
                        Performing challenge...
                      </div>
                      <div className="text-sm text-gray-600">
                        {sessionData.liveness_challenge.instruction}
                      </div>
                    </div>
                  )}
                </div>
              </div>
            </div>
          )}

          {/* Error Display */}
          {error && cameraState !== 'error' && (
            <div className="p-4 bg-red-50 border border-red-200 rounded-lg m-6">
              <div className="flex">
                <XMarkIcon className="w-5 h-5 text-red-400 mr-2 mt-0.5" />
                <p className="text-red-700 text-sm">{error}</p>
              </div>
            </div>
          )}
        </div>

        {/* Instructions */}
        <div className="mt-8 bg-blue-50 rounded-xl p-6">
          <h3 className="text-lg font-semibold text-blue-900 mb-4">ðŸ”§ OpenCV Live Capture</h3>
          <ul className="text-blue-800 space-y-2">
            <li className="flex items-start">
              <span className="text-blue-500 mr-2 mt-1">â€¢</span>
              <span>This system uses OpenCV for reliable camera processing</span>
            </li>
            <li className="flex items-start">
              <span className="text-blue-500 mr-2 mt-1">â€¢</span>
              <span>Ensure good lighting on your face</span>
            </li>
            <li className="flex items-start">
              <span className="text-blue-500 mr-2 mt-1">â€¢</span>
              <span>Position your face in the center circle</span>
            </li>
            <li className="flex items-start">
              <span className="text-blue-500 mr-2 mt-1">â€¢</span>
              <span>Wait for the green circle indicating face detection</span>
            </li>
          </ul>
          
          {debugInfo && (
            <div className="mt-4 p-3 bg-gray-100 rounded-lg">
              <p className="text-sm text-gray-600">Status: {debugInfo}</p>
              {cameraState === 'ready' && (
                <button
                  onClick={retryCamera}
                  className="mt-2 px-3 py-1 text-xs bg-blue-500 text-white rounded hover:bg-blue-600"
                >
                  Restart Camera
                </button>
              )}
            </div>
          )}
        </div>
      </div>
    </div>
  );
};