// Optional imports with type safety
let faceapi: any = null;
let Canvas: any = null;
let Image: any = null;
let createCanvas: any = null;
let loadImage: any = null;

try {
  const faceapiModule = await import('@vladmandic/face-api');
  faceapi = faceapiModule;
} catch (error) {
  console.log('‚ö†Ô∏è  @vladmandic/face-api not available');
}

try {
  const canvasModule = await import('canvas');
  Canvas = canvasModule.Canvas;
  Image = canvasModule.Image;
  createCanvas = canvasModule.createCanvas;
  loadImage = canvasModule.loadImage;
} catch (error) {
  console.log('‚ö†Ô∏è  canvas not available');
}
import { logger } from '@/utils/logger.js';
import { StorageService } from './storage.js';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configure face-api.js for Node.js environment if available
if (faceapi && Canvas && Image) {
  // @ts-ignore
  faceapi.env.monkeyPatch({ Canvas, Image });
}

interface FaceDescriptor {
  descriptor: Float32Array;
  detection: any;
  landmarks?: any;
}

interface FaceComparisonResult {
  similarity: number;
  confidence: number;
  isMatch: boolean;
  details: {
    face1Detected: boolean;
    face2Detected: boolean;
    distance: number;
    landmarks1Count?: number;
    landmarks2Count?: number;
  };
}

interface LivenessDetectionResult {
  isLive: boolean;
  score: number;
  confidence: number;
  analysis: {
    faceDetected: boolean;
    facialSymmetry: number;
    eyeOpenness: number;
    facialExpression: string;
    imageQuality: number;
    multipleFactorsScore: number;
  };
  riskFactors: string[];
}

export class ModernFaceRecognitionService {
  private storageService: StorageService;
  private isInitialized: boolean = false;
  private modelsPath: string;

  // Thresholds for face recognition
  private readonly FACE_DETECTION_SCORE_THRESHOLD = 0.5;
  private readonly FACE_SIMILARITY_THRESHOLD = 0.6; // Lower means more similar
  private readonly HIGH_CONFIDENCE_THRESHOLD = 0.4;
  private readonly MEDIUM_CONFIDENCE_THRESHOLD = 0.5;

  constructor() {
    this.storageService = new StorageService();
    this.modelsPath = path.join(__dirname, '../../models');
    console.log('üéØ Modern Face Recognition Service initialized');
    console.log('üìÇ Models path:', this.modelsPath);
  }

  /**
   * Initialize the face recognition models
   */
  async initialize(): Promise<void> {
    if (this.isInitialized) {
      return;
    }

    try {
      logger.info('Loading face recognition models...');
      console.log('üì¶ Loading face recognition models...');

      // Load all required models
      await Promise.all([
        faceapi.nets.ssdMobilenetv1.loadFromUri(this.modelsPath),
        faceapi.nets.faceLandmark68Net.loadFromUri(this.modelsPath),
        faceapi.nets.faceRecognitionNet.loadFromUri(this.modelsPath),
        faceapi.nets.faceExpressionNet.loadFromUri(this.modelsPath),
        faceapi.nets.ageGenderNet.loadFromUri(this.modelsPath)
      ]);

      this.isInitialized = true;
      console.log('‚úÖ Face recognition models loaded successfully');
      logger.info('Face recognition models loaded successfully');

    } catch (error) {
      console.error('‚ùå Failed to load face recognition models:', error);
      logger.error('Failed to load face recognition models:', error);

      // Download models if they don't exist
      await this.downloadModelsIfNeeded();
      throw new Error('Face recognition models not available. Please ensure models are downloaded.');
    }
  }

  /**
   * Download face recognition models if they don't exist
   */
  private async downloadModelsIfNeeded(): Promise<void> {
    const fs = await import('fs');
    
    if (!fs.existsSync(this.modelsPath)) {
      fs.mkdirSync(this.modelsPath, { recursive: true });
    }

    logger.warn('Face recognition models not found. You need to download them manually.');
    console.log(`‚ö†Ô∏è  Face recognition models not found at: ${this.modelsPath}`);
    console.log('üì• Please download models from: https://github.com/vladmandic/face-api/tree/master/model');
    console.log('   Required models:');
    console.log('   - ssd_mobilenetv1_model-*.json/bin');
    console.log('   - face_landmark_68_model-*.json/bin');
    console.log('   - face_recognition_model-*.json/bin');
    console.log('   - face_expression_model-*.json/bin');
    console.log('   - age_gender_model-*.json/bin');
  }

  /**
   * Extract face descriptor from an image
   */
  private async extractFaceDescriptor(imagePath: string): Promise<FaceDescriptor | null> {
    try {
      // Load image from storage
      const imageBuffer = await this.storageService.downloadFile(imagePath);
      const image = await loadImage(imageBuffer);

      // Detect face with landmarks and descriptor
      const detection = await faceapi
        .detectSingleFace(image as any)
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!detection) {
        console.log(`‚ùå No face detected in image: ${path.basename(imagePath)}`);
        return null;
      }

      if (detection.detection.score < this.FACE_DETECTION_SCORE_THRESHOLD) {
        console.log(`‚ùå Face detection confidence too low: ${detection.detection.score} < ${this.FACE_DETECTION_SCORE_THRESHOLD}`);
        return null;
      }

      console.log(`‚úÖ Face detected with confidence: ${detection.detection.score.toFixed(3)}`);

      return {
        descriptor: detection.descriptor,
        detection: detection.detection,
        landmarks: detection.landmarks
      };

    } catch (error) {
      console.error(`‚ùå Error extracting face descriptor from ${imagePath}:`, error);
      logger.error('Face descriptor extraction failed:', error);
      return null;
    }
  }

  /**
   * Compare two face descriptors
   */
  private compareFaceDescriptors(desc1: Float32Array, desc2: Float32Array): number {
    // Calculate Euclidean distance between descriptors
    let sum = 0;
    for (let i = 0; i < desc1.length; i++) {
      sum += Math.pow(desc1[i] - desc2[i], 2);
    }
    return Math.sqrt(sum);
  }

  /**
   * Compare faces in two images
   */
  async compareFaces(imagePath1: string, imagePath2: string): Promise<number> {
    await this.initialize();

    console.log('üîç Starting modern face comparison...');
    console.log(`   üì∏ Image 1: ${path.basename(imagePath1)}`);
    console.log(`   üì∏ Image 2: ${path.basename(imagePath2)}`);

    try {
      // Extract face descriptors from both images
      const [face1, face2] = await Promise.all([
        this.extractFaceDescriptor(imagePath1),
        this.extractFaceDescriptor(imagePath2)
      ]);

      if (!face1 || !face2) {
        console.log('‚ùå Could not detect faces in one or both images');
        logger.warn('Face comparison failed - faces not detected', {
          image1: imagePath1,
          image2: imagePath2,
          face1Detected: !!face1,
          face2Detected: !!face2
        });
        return 0.0; // Return failure score when faces aren't detected
      }

      // Compare face descriptors
      const distance = this.compareFaceDescriptors(face1.descriptor, face2.descriptor);
      
      // Convert distance to similarity score (0-1, where 1 is perfect match)
      // Lower distance = higher similarity
      const similarity = Math.max(0, 1 - (distance / 1.5)); // Normalize distance

      const isMatch = distance < this.FACE_SIMILARITY_THRESHOLD;
      const confidence = distance < this.HIGH_CONFIDENCE_THRESHOLD ? 0.95 :
                        distance < this.MEDIUM_CONFIDENCE_THRESHOLD ? 0.80 : 0.60;

      console.log(`üìä Face Comparison Results:`);
      console.log(`   üìè Distance: ${distance.toFixed(4)}`);
      console.log(`   üìà Similarity: ${similarity.toFixed(4)}`);
      console.log(`   üéØ Match: ${isMatch ? '‚úÖ YES' : '‚ùå NO'}`);
      console.log(`   üîí Confidence: ${confidence.toFixed(3)}`);

      logger.info('Face comparison completed', {
        imagePath1,
        imagePath2,
        distance,
        similarity,
        isMatch,
        confidence,
        face1Score: face1.detection.score,
        face2Score: face2.detection.score
      });

      return similarity;

    } catch (error) {
      console.error('‚ùå Modern face comparison failed:', error);
      logger.error('Modern face comparison failed:', error);
      return 0.0; // Return failure score on error
    }
  }

  /**
   * Detect liveness in an image using multiple factors
   */
  async detectLiveness(imagePath: string): Promise<number> {
    await this.initialize();

    console.log('üëÅÔ∏è  Starting modern liveness detection...');
    console.log(`   üì∏ Image: ${path.basename(imagePath)}`);

    try {
      // Load image from storage
      const imageBuffer = await this.storageService.downloadFile(imagePath);
      const image = await loadImage(imageBuffer);

      // Detect face with all features
      const detection = await faceapi
        .detectSingleFace(image as any)
        .withFaceLandmarks()
        .withFaceExpressions()
        .withAgeAndGender();

      if (!detection) {
        console.log('‚ùå No face detected for liveness analysis');
        return 0.0;
      }

      // Calculate various liveness indicators
      const livenessScore = this.calculateLivenessScore(detection, image);

      console.log(`üëÅÔ∏è  Liveness Detection Results:`);
      console.log(`   üìä Overall Score: ${livenessScore.toFixed(4)}`);
      console.log(`   üéØ Face Detected: ${detection.detection.score.toFixed(3)}`);
      
      if (detection.expressions) {
        const topExpression = Object.entries(detection.expressions)
          .sort(([,a], [,b]) => (b as number) - (a as number))[0];
        console.log(`   üòä Top Expression: ${topExpression[0]} (${(topExpression[1] as number).toFixed(3)})`);
      }

      logger.info('Liveness detection completed', {
        imagePath,
        livenessScore,
        faceScore: detection.detection.score,
        expressions: detection.expressions
      });

      return livenessScore;

    } catch (error) {
      console.error('‚ùå Modern liveness detection failed:', error);
      logger.error('Modern liveness detection failed:', error);
      return 0.0; // Return failure score on error
    }
  }

  /**
   * Calculate liveness score based on multiple factors
   */
  private calculateLivenessScore(detection: any, image: any): number {
    let score = 0;
    let factorCount = 0;

    // Factor 1: Face detection confidence
    const faceConfidence = detection.detection.score;
    score += faceConfidence * 0.3;
    factorCount += 0.3;

    console.log(`   üéØ Face Confidence: ${faceConfidence.toFixed(3)} (weight: 0.3)`);

    // Factor 2: Facial landmarks quality
    if (detection.landmarks) {
      const landmarkQuality = this.assessLandmarkQuality(detection.landmarks);
      score += landmarkQuality * 0.25;
      factorCount += 0.25;
      console.log(`   üó∫Ô∏è  Landmark Quality: ${landmarkQuality.toFixed(3)} (weight: 0.25)`);
    }

    // Factor 3: Expression naturalness
    if (detection.expressions) {
      const expressionNaturalness = this.assessExpressionNaturalness(detection.expressions);
      score += expressionNaturalness * 0.2;
      factorCount += 0.2;
      console.log(`   üòä Expression Naturalness: ${expressionNaturalness.toFixed(3)} (weight: 0.2)`);
    }

    // Factor 4: Age/Gender detection (indicates realistic face)
    if (detection.age && detection.gender) {
      const demographicScore = Math.min(1.0, detection.genderProbability);
      score += demographicScore * 0.15;
      factorCount += 0.15;
      console.log(`   üë§ Demographic Score: ${demographicScore.toFixed(3)} (weight: 0.15)`);
      console.log(`   üìÖ Detected Age: ${Math.round(detection.age)}, Gender: ${detection.gender}`);
    }

    // Factor 5: Image quality indicators
    const imageQuality = this.assessImageQuality(image);
    score += imageQuality * 0.1;
    factorCount += 0.1;
    console.log(`   üì∑ Image Quality: ${imageQuality.toFixed(3)} (weight: 0.1)`);

    // Normalize score
    const normalizedScore = factorCount > 0 ? score / factorCount : 0;
    const finalScore = Math.max(0, Math.min(1, normalizedScore));

    console.log(`   üìä Weighted Score: ${score.toFixed(3)} / ${factorCount.toFixed(2)} = ${finalScore.toFixed(3)}`);

    return finalScore;
  }

  /**
   * Assess the quality of facial landmarks
   */
  private assessLandmarkQuality(landmarks: any): number {
    const points = landmarks.positions;
    
    // Check if we have all expected landmark points
    if (points.length < 68) {
      return 0.3; // Low quality if missing landmarks
    }

    // Calculate landmark spread (wider spread indicates better detection)
    const xs = points.map((p: any) => p.x);
    const ys = points.map((p: any) => p.y);
    const xRange = Math.max(...xs) - Math.min(...xs);
    const yRange = Math.max(...ys) - Math.min(...ys);
    
    // Normalize spread score (assume reasonable face size)
    const spreadScore = Math.min(1.0, (xRange + yRange) / 400);
    
    // Check for unrealistic landmark clustering
    const avgX = xs.reduce((a: number, b: number) => a + b) / xs.length;
    const avgY = ys.reduce((a: number, b: number) => a + b) / ys.length;
    const deviations = points.map((p: any) => 
      Math.sqrt(Math.pow(p.x - avgX, 2) + Math.pow(p.y - avgY, 2))
    );
    const avgDeviation = deviations.reduce((a: number, b: number) => a + b) / deviations.length;
    const consistencyScore = Math.min(1.0, avgDeviation / 50);

    return (spreadScore + consistencyScore) / 2;
  }

  /**
   * Assess naturalness of facial expressions
   */
  private assessExpressionNaturalness(expressions: any): number {
    const expressionValues = Object.values(expressions) as number[];
    
    // Natural faces usually have some variation in expressions, not all neutral
    const maxExpression = Math.max(...expressionValues);
    const expressionVariety = expressionValues.filter((v: number) => v > 0.1).length;
    
    // Avoid completely flat or overly extreme expressions
    const naturalness = expressionVariety > 1 && maxExpression < 0.9 ? 0.8 : 0.5;
    
    return naturalness;
  }

  /**
   * Assess overall image quality
   */
  private assessImageQuality(image: any): number {
    // Basic image quality assessment
    // This is simplified - in production you might want more sophisticated analysis
    
    if (!image.width || !image.height) {
      return 0.3;
    }

    // Check resolution
    const pixelCount = image.width * image.height;
    const resolutionScore = Math.min(1.0, pixelCount / (300 * 300)); // Minimum 300x300 is good

    // For now, just return resolution score
    // Could be extended with sharpness, brightness, contrast analysis
    return resolutionScore;
  }

  /**
   * Get detailed face comparison results
   */
  async getDetailedFaceComparison(imagePath1: string, imagePath2: string): Promise<FaceComparisonResult> {
    await this.initialize();

    try {
      const [face1, face2] = await Promise.all([
        this.extractFaceDescriptor(imagePath1),
        this.extractFaceDescriptor(imagePath2)
      ]);

      const result: FaceComparisonResult = {
        similarity: 0,
        confidence: 0,
        isMatch: false,
        details: {
          face1Detected: !!face1,
          face2Detected: !!face2,
          distance: Infinity,
          landmarks1Count: face1?.landmarks?.positions.length,
          landmarks2Count: face2?.landmarks?.positions.length
        }
      };

      if (!face1 || !face2) {
        return result;
      }

      const distance = this.compareFaceDescriptors(face1.descriptor, face2.descriptor);
      const similarity = Math.max(0, 1 - (distance / 1.5));

      result.similarity = similarity;
      result.confidence = distance < this.HIGH_CONFIDENCE_THRESHOLD ? 0.95 :
                         distance < this.MEDIUM_CONFIDENCE_THRESHOLD ? 0.80 : 0.60;
      result.isMatch = distance < this.FACE_SIMILARITY_THRESHOLD;
      result.details.distance = distance;

      return result;

    } catch (error) {
      logger.error('Detailed face comparison failed:', error);
      return {
        similarity: 0,
        confidence: 0,
        isMatch: false,
        details: {
          face1Detected: false,
          face2Detected: false,
          distance: Infinity
        }
      };
    }
  }

  /**
   * Health check for the service
   */
  async healthCheck(): Promise<{ status: string; modelsLoaded: boolean; error?: string }> {
    try {
      await this.initialize();
      return {
        status: 'healthy',
        modelsLoaded: this.isInitialized
      };
    } catch (error) {
      return {
        status: 'error',
        modelsLoaded: false,
        error: error instanceof Error ? error.message : 'Unknown error'
      };
    }
  }
}